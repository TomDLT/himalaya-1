
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiple kernel ridge with scikit-learn API &#8212; Himalaya 0.3.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multiple kernel ridge solvers" href="plot_mkr_solvers.html" />
    <link rel="prev" title="Multiple kernel ridge regression" href="plot_mkr_random_search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/logo.svg" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=himalaya&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Gallery of examples</a><ul>
      <li>Previous: <a href="plot_mkr_random_search.html" title="previous chapter">Multiple kernel ridge regression</a></li>
      <li>Next: <a href="plot_mkr_solvers.html" title="next chapter">Multiple kernel ridge solvers</a></li>
  </ul></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Gallery of examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#kernel-ridge-regression">Kernel ridge regression</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#multiple-kernel-ridge-regression">Multiple kernel ridge regression</a></li>
</ul>
</li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-multiple-kernel-ridge-plot-mkr-sklearn-api-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiple-kernel-ridge-with-scikit-learn-api">
<span id="sphx-glr-auto-examples-multiple-kernel-ridge-plot-mkr-sklearn-api-py"></span><h1>Multiple kernel ridge with scikit-learn API<a class="headerlink" href="#multiple-kernel-ridge-with-scikit-learn-api" title="Permalink to this headline">¶</a></h1>
<p>This example demonstrates how to solve multiple kernel ridge regression, using
scikit-learn API.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">MultipleKernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">Kernelizer</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">ColumnKernelizer</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
</pre></div>
</div>
<p>In this example, we use the <code class="docutils literal notranslate"><span class="pre">torch</span></code> backend.</p>
<p>Torch can perform computations both on CPU and GPU.
To use the CPU, use the “torch” backend.
To use GPU, you can either use the “torch” backend and move your data to GPU
with the <code class="docutils literal notranslate"><span class="pre">.cuda</span></code> method, or you can use the “torch_cuda” backend which calls
this method in <code class="docutils literal notranslate"><span class="pre">backend.asarray</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="generate-a-random-dataset">
<h2>Generate a random dataset<a class="headerlink" href="#generate-a-random-dataset" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Xs_train : list of arrays of shape (n_samples_train, n_features)</p></li>
<li><p>Xs_test : list of arrays of shape (n_samples_test, n_features)</p></li>
<li><p>Y_train : array of shape (n_samples_train, n_targets)</p></li>
<li><p>Y_test : array of shape (n_repeat, n_samples_test, n_targets)</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples_train</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_samples_test</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">n_targets</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_features_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature space A&quot;</span><span class="p">,</span> <span class="s2">&quot;feature space B&quot;</span><span class="p">,</span> <span class="s2">&quot;feature space C&quot;</span><span class="p">]</span>

<span class="n">Xs_train</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">n_features</span> <span class="ow">in</span> <span class="n">n_features_list</span>
<span class="p">]</span>
<span class="n">Xs_test</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_test</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">for</span> <span class="n">n_features</span> <span class="ow">in</span> <span class="n">n_features_list</span>
<span class="p">]</span>
<span class="n">ws</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_features</span>
    <span class="k">for</span> <span class="n">n_features</span> <span class="ow">in</span> <span class="n">n_features_list</span>
<span class="p">]</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">ws</span><span class="p">)])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">ws</span><span class="p">)])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Optional: Add some arbitrary scalings per kernel</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">scalings</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Xs_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span> <span class="o">*</span> <span class="n">scaling</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">scaling</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">scalings</span><span class="p">)]</span>
    <span class="n">Xs_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span> <span class="o">*</span> <span class="n">scaling</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">scaling</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">scalings</span><span class="p">)]</span>
</pre></div>
</div>
<p>Concatenate the feature spaces and move to GPU with <code class="docutils literal notranslate"><span class="pre">backend.asarray</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">backend</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">backend</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We could precompute the kernels by hand on <code class="docutils literal notranslate"><span class="pre">Xs_train</span></code>, as done in
<code class="docutils literal notranslate"><span class="pre">plot_mkr_random_search.py</span></code>. Instead, here we use the
<code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code> to make a <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the start and end of each feature space X in Xs</span>
<span class="n">start_and_end</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">n_features_list</span><span class="p">)])</span>
<span class="n">slices</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">start_and_end</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">start_and_end</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Create a different <code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code> for each feature space. Here we use a
linear kernel for all feature spaces, but <code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code> accepts any
<code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code>, or <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> ending with a
<code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kernelizers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">Kernelizer</span><span class="p">(),</span> <span class="n">slice_</span><span class="p">)</span>
               <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">slice_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">slices</span><span class="p">)]</span>
<span class="n">column_kernelizer</span> <span class="o">=</span> <span class="n">ColumnKernelizer</span><span class="p">(</span><span class="n">kernelizers</span><span class="p">)</span>

<span class="c1"># Note that ``ColumnKernelizer`` has a parameter ``n_jobs`` to parallelize each</span>
<span class="c1"># kernelizer, yet such parallelism does not work with GPU arrays.</span>
</pre></div>
</div>
</div>
<div class="section" id="define-the-model">
<h2>Define the model<a class="headerlink" href="#define-the-model" title="Permalink to this headline">¶</a></h2>
<p>The class takes a number of common parameters during initialization, such as
<cite>kernels</cite> or <cite>solver</cite>. Since the solver parameters might be different
depending on the solver, they can be passed in the <cite>solver_params</cite> parameter.</p>
<p>Here we use the “random_search” solver.
We can check its specific parameters in the function docstring:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">solver_function</span> <span class="o">=</span> <span class="n">MultipleKernelRidgeCV</span><span class="o">.</span><span class="n">ALL_SOLVERS</span><span class="p">[</span><span class="s2">&quot;random_search&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Docstring of the function </span><span class="si">%s</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="n">solver_function</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">solver_function</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Docstring of the function solve_multiple_kernel_ridge_random_search:
Solve multiple kernel ridge regression using random search.

    Parameters
    ----------
    Ks : array of shape (n_kernels, n_samples, n_samples)
        Input kernels.
    Y : array of shape (n_samples, n_targets)
        Target data.
    n_iter : int, or array of shape (n_iter, n_kernels)
        Number of kernel weights combination to search.
        If an array is given, the solver uses it as the list of kernel weights
        to try, instead of sampling from a Dirichlet distribution.
    concentration : float, or list of float
        Concentration parameters of the Dirichlet distribution.
        If a list, iteratively cycle through the list.
        Not used if n_iter is an array.
    alphas : float or array of shape (n_alphas, )
        Range of ridge regularization parameter.
    score_func : callable
        Function used to compute the score of predictions versus Y.
    cv : int or scikit-learn splitter
        Cross-validation splitter. If an int, KFold is used.
    fit_intercept : boolean
        Whether to fit an intercept. If False, Ks should be centered
        (see KernelCenterer), and Y must be zero-mean over samples.
        Only available if return_weights == &#39;dual&#39;.
    return_weights : None, &#39;primal&#39;, or &#39;dual&#39;
        Whether to refit on the entire dataset and return the weights.
    Xs : array of shape (n_kernels, n_samples, n_features) or None
        Necessary if return_weights == &#39;primal&#39;.
    local_alpha : bool
        If True, alphas are selected per target, else shared over all targets.
    jitter_alphas : bool
        If True, alphas range is slightly jittered for each gamma.
    random_state : int, or None
        Random generator seed. Use an int for deterministic search.
    n_targets_batch : int or None
        Size of the batch for over targets during cross-validation.
        Used for memory reasons. If None, uses all n_targets at once.
    n_targets_batch_refit : int or None
        Size of the batch for over targets during refit.
        Used for memory reasons. If None, uses all n_targets at once.
    n_alphas_batch : int or None
        Size of the batch for over alphas. Used for memory reasons.
        If None, uses all n_alphas at once.
    progress_bar : bool
        If True, display a progress bar over gammas.
    Ks_in_cpu : bool
        If True, keep Ks in CPU memory to limit GPU memory (slower).
        This feature is not available through the scikit-learn API.
    conservative : bool
        If True, when selecting the hyperparameter alpha, take the largest one
        that is less than one standard deviation away from the best.
        If False, take the best.
    Y_in_cpu : bool
        If True, keep the target values ``Y`` in CPU memory (slower).
    diagonalize_method : str in {&quot;eigh&quot;, &quot;svd&quot;}
        Method used to diagonalize the kernel.
    return_alphas : bool
        If True, return the best alpha value for each target.

    Returns
    -------
    deltas : array of shape (n_kernels, n_targets)
        Best log kernel weights for each target.
    refit_weights : array or None
        Refit regression weights on the entire dataset, using selected best
        hyperparameters. Refit weights are always stored on CPU memory.
        If return_weights == &#39;primal&#39;, shape is (n_features, n_targets),
        if return_weights == &#39;dual&#39;, shape is (n_samples, n_targets),
        else, None.
    cv_scores : array of shape (n_iter, n_targets)
        Cross-validation scores per iteration, averaged over splits, for the
        best alpha. Cross-validation scores will always be on CPU memory.
    best_alphas : array of shape (n_targets, )
        Best alpha value per target. Only returned if return_alphas is True.
    intercept : array of shape (n_targets,)
        Intercept. Only returned when fit_intercept is True.
</pre></div>
</div>
<p>We use 100 iterations to have a reasonably fast example (~40 sec).
To have a better convergence, we probably need more iterations.
Note that there is currently no stopping criterion in this method.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<p>Grid of regularization parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">41</span><span class="p">)</span>
</pre></div>
</div>
<p>Batch parameters are used to reduce the necessary GPU memory. A larger value
will be a bit faster, but the solver might crash if it runs out of memory.
Optimal values depend on the size of your dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_targets_batch</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_alphas_batch</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_targets_batch_refit</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">solver_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
                     <span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span>
                     <span class="n">n_alphas_batch</span><span class="o">=</span><span class="n">n_alphas_batch</span><span class="p">,</span>
                     <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="n">n_targets_batch_refit</span><span class="p">,</span>
                     <span class="n">jitter_alphas</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MultipleKernelRidgeCV</span><span class="p">(</span><span class="n">kernels</span><span class="o">=</span><span class="s2">&quot;precomputed&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;random_search&quot;</span><span class="p">,</span>
                              <span class="n">solver_params</span><span class="o">=</span><span class="n">solver_params</span><span class="p">)</span>
</pre></div>
</div>
<p>Define and fit the pipeline</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">column_kernelizer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[                                        ] 0% | 0.00 sec | 100 random sampling with cv |
[                                        ] 1% | 0.29 sec | 100 random sampling with cv |
[                                        ] 2% | 0.59 sec | 100 random sampling with cv |
[.                                       ] 3% | 0.82 sec | 100 random sampling with cv |
[.                                       ] 4% | 1.12 sec | 100 random sampling with cv |
[..                                      ] 5% | 1.41 sec | 100 random sampling with cv |
[..                                      ] 6% | 1.64 sec | 100 random sampling with cv |
[..                                      ] 7% | 1.88 sec | 100 random sampling with cv |
[...                                     ] 8% | 2.18 sec | 100 random sampling with cv |
[...                                     ] 9% | 2.50 sec | 100 random sampling with cv |
[....                                    ] 10% | 2.73 sec | 100 random sampling with cv |
[....                                    ] 11% | 2.97 sec | 100 random sampling with cv |
[....                                    ] 12% | 3.29 sec | 100 random sampling with cv |
[.....                                   ] 13% | 3.51 sec | 100 random sampling with cv |
[.....                                   ] 14% | 3.74 sec | 100 random sampling with cv |
[......                                  ] 15% | 3.96 sec | 100 random sampling with cv |
[......                                  ] 16% | 4.19 sec | 100 random sampling with cv |
[......                                  ] 17% | 4.43 sec | 100 random sampling with cv |
[.......                                 ] 18% | 4.66 sec | 100 random sampling with cv |
[.......                                 ] 19% | 4.89 sec | 100 random sampling with cv |
[........                                ] 20% | 5.12 sec | 100 random sampling with cv |
[........                                ] 21% | 5.34 sec | 100 random sampling with cv |
[........                                ] 22% | 5.58 sec | 100 random sampling with cv |
[.........                               ] 23% | 5.83 sec | 100 random sampling with cv |
[.........                               ] 24% | 6.07 sec | 100 random sampling with cv |
[..........                              ] 25% | 6.30 sec | 100 random sampling with cv |
[..........                              ] 26% | 6.55 sec | 100 random sampling with cv |
[..........                              ] 27% | 6.78 sec | 100 random sampling with cv |
[...........                             ] 28% | 7.02 sec | 100 random sampling with cv |
[...........                             ] 29% | 7.26 sec | 100 random sampling with cv |
[............                            ] 30% | 7.50 sec | 100 random sampling with cv |
[............                            ] 31% | 7.73 sec | 100 random sampling with cv |
[............                            ] 32% | 7.96 sec | 100 random sampling with cv |
[.............                           ] 33% | 8.20 sec | 100 random sampling with cv |
[.............                           ] 34% | 8.44 sec | 100 random sampling with cv |
[..............                          ] 35% | 8.74 sec | 100 random sampling with cv |
[..............                          ] 36% | 9.06 sec | 100 random sampling with cv |
[..............                          ] 37% | 9.34 sec | 100 random sampling with cv |
[...............                         ] 38% | 9.63 sec | 100 random sampling with cv |
[...............                         ] 39% | 9.91 sec | 100 random sampling with cv |
[................                        ] 40% | 10.11 sec | 100 random sampling with cv |
[................                        ] 41% | 10.31 sec | 100 random sampling with cv |
[................                        ] 42% | 10.52 sec | 100 random sampling with cv |
[.................                       ] 43% | 10.67 sec | 100 random sampling with cv |
[.................                       ] 44% | 10.87 sec | 100 random sampling with cv |
[..................                      ] 45% | 11.08 sec | 100 random sampling with cv |
[..................                      ] 46% | 11.28 sec | 100 random sampling with cv |
[..................                      ] 47% | 11.46 sec | 100 random sampling with cv |
[...................                     ] 48% | 11.66 sec | 100 random sampling with cv |
[...................                     ] 49% | 11.87 sec | 100 random sampling with cv |
[....................                    ] 50% | 12.07 sec | 100 random sampling with cv |
[....................                    ] 51% | 12.27 sec | 100 random sampling with cv |
[....................                    ] 52% | 12.48 sec | 100 random sampling with cv |
[.....................                   ] 53% | 12.68 sec | 100 random sampling with cv |
[.....................                   ] 54% | 12.88 sec | 100 random sampling with cv |
[......................                  ] 55% | 13.09 sec | 100 random sampling with cv |
[......................                  ] 56% | 13.38 sec | 100 random sampling with cv |
[......................                  ] 57% | 13.58 sec | 100 random sampling with cv |
[.......................                 ] 58% | 13.79 sec | 100 random sampling with cv |
[.......................                 ] 59% | 14.04 sec | 100 random sampling with cv |
[........................                ] 60% | 14.24 sec | 100 random sampling with cv |
[........................                ] 61% | 14.43 sec | 100 random sampling with cv |
[........................                ] 62% | 14.63 sec | 100 random sampling with cv |
[.........................               ] 63% | 14.82 sec | 100 random sampling with cv |
[.........................               ] 64% | 15.03 sec | 100 random sampling with cv |
[..........................              ] 65% | 15.23 sec | 100 random sampling with cv |
[..........................              ] 66% | 15.44 sec | 100 random sampling with cv |
[..........................              ] 67% | 15.64 sec | 100 random sampling with cv |
[...........................             ] 68% | 15.84 sec | 100 random sampling with cv |
[...........................             ] 69% | 16.04 sec | 100 random sampling with cv |
[............................            ] 70% | 16.25 sec | 100 random sampling with cv |
[............................            ] 71% | 16.44 sec | 100 random sampling with cv |
[............................            ] 72% | 16.64 sec | 100 random sampling with cv |
[.............................           ] 73% | 16.85 sec | 100 random sampling with cv |
[.............................           ] 74% | 17.05 sec | 100 random sampling with cv |
[..............................          ] 75% | 17.25 sec | 100 random sampling with cv |
[..............................          ] 76% | 17.45 sec | 100 random sampling with cv |
[..............................          ] 77% | 17.66 sec | 100 random sampling with cv |
[...............................         ] 78% | 17.86 sec | 100 random sampling with cv |
[...............................         ] 79% | 18.06 sec | 100 random sampling with cv |
[................................        ] 80% | 18.27 sec | 100 random sampling with cv |
[................................        ] 81% | 18.47 sec | 100 random sampling with cv |
[................................        ] 82% | 18.67 sec | 100 random sampling with cv |
[.................................       ] 83% | 18.88 sec | 100 random sampling with cv |
[.................................       ] 84% | 19.08 sec | 100 random sampling with cv |
[..................................      ] 85% | 19.29 sec | 100 random sampling with cv |
[..................................      ] 86% | 19.49 sec | 100 random sampling with cv |
[..................................      ] 87% | 19.69 sec | 100 random sampling with cv |
[...................................     ] 88% | 19.89 sec | 100 random sampling with cv |
[...................................     ] 89% | 20.09 sec | 100 random sampling with cv |
[....................................    ] 90% | 20.29 sec | 100 random sampling with cv |
[....................................    ] 91% | 20.50 sec | 100 random sampling with cv |
[....................................    ] 92% | 20.70 sec | 100 random sampling with cv |
[.....................................   ] 93% | 20.90 sec | 100 random sampling with cv |
[.....................................   ] 94% | 21.11 sec | 100 random sampling with cv |
[......................................  ] 95% | 21.31 sec | 100 random sampling with cv |
[......................................  ] 96% | 21.51 sec | 100 random sampling with cv |
[......................................  ] 97% | 21.77 sec | 100 random sampling with cv |
[....................................... ] 98% | 21.97 sec | 100 random sampling with cv |
[....................................... ] 99% | 22.17 sec | 100 random sampling with cv |
[........................................] 100% | 22.37 sec | 100 random sampling with cv |

Pipeline(steps=[(&#39;columnkernelizer&#39;,
                 ColumnKernelizer(transformers=[(&#39;feature space A&#39;,
                                                 Kernelizer(),
                                                 slice(0, 1000, None)),
                                                (&#39;feature space B&#39;,
                                                 Kernelizer(),
                                                 slice(1000, 2000, None)),
                                                (&#39;feature space C&#39;,
                                                 Kernelizer(),
                                                 slice(2000, 2500, None))])),
                (&#39;multiplekernelridgecv&#39;,
                 MultipleKernelRidgeCV(kernels=&#39;precomputed&#39;,
                                       solver_params={&#39;alphas&#39;: array([1.00000000e-10, 3.1622776...
       1.00000000e+02, 3.16227766e+02, 1.00000000e+03, 3.16227766e+03,
       1.00000000e+04, 3.16227766e+04, 1.00000000e+05, 3.16227766e+05,
       1.00000000e+06, 3.16227766e+06, 1.00000000e+07, 3.16227766e+07,
       1.00000000e+08, 3.16227766e+08, 1.00000000e+09, 3.16227766e+09,
       1.00000000e+10]),
                                                      &#39;jitter_alphas&#39;: True,
                                                      &#39;n_alphas_batch&#39;: 20,
                                                      &#39;n_iter&#39;: 100,
                                                      &#39;n_targets_batch&#39;: 1000,
                                                      &#39;n_targets_batch_refit&#39;: 200}))])
</pre></div>
</div>
</div>
<div class="section" id="plot-the-convergence-curve">
<h2>Plot the convergence curve<a class="headerlink" href="#plot-the-convergence-curve" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># ``cv_scores`` gives the scores for each sampled kernel weights.</span>
<span class="c1"># The convergence curve is thus the current maximum for each target.</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">pipe</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">)</span>
<span class="n">current_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean_current_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">current_max</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean_current_max</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_array</span><span class="p">,</span> <span class="n">mean_current_max</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of kernel weights sampled&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;L2 negative loss (higher is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Convergence curve, averaged over targets&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Convergence curve, averaged over targets" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mkr_sklearn_api_001.png" />
</div>
<div class="section" id="compare-to-kernelridgecv">
<h2>Compare to <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code><a class="headerlink" href="#compare-to-kernelridgecv" title="Permalink to this headline">¶</a></h2>
<p>Compare to a baseline <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code> model with all the concatenated features.
Comparison is performed using the prediction scores on the test set.</p>
<p>Fit the baseline model <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">baseline</span> <span class="o">=</span> <span class="n">KernelRidgeCV</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">)</span>
<span class="n">baseline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>KernelRidgeCV(alphas=array([1.00000000e-10, 3.16227766e-10, 1.00000000e-09, 3.16227766e-09,
       1.00000000e-08, 3.16227766e-08, 1.00000000e-07, 3.16227766e-07,
       1.00000000e-06, 3.16227766e-06, 1.00000000e-05, 3.16227766e-05,
       1.00000000e-04, 3.16227766e-04, 1.00000000e-03, 3.16227766e-03,
       1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,
       1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,
       1.00000000e+02, 3.16227766e+02, 1.00000000e+03, 3.16227766e+03,
       1.00000000e+04, 3.16227766e+04, 1.00000000e+05, 3.16227766e+05,
       1.00000000e+06, 3.16227766e+06, 1.00000000e+07, 3.16227766e+07,
       1.00000000e+08, 3.16227766e+08, 1.00000000e+09, 3.16227766e+09,
       1.00000000e+10]))
</pre></div>
</div>
<p>Compute scores of both models</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

<span class="n">scores_baseline</span> <span class="o">=</span> <span class="n">baseline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_baseline</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_baseline</span><span class="p">)</span>
</pre></div>
</div>
<p>Plot histograms</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">scores_baseline</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
                   <span class="nb">max</span><span class="p">(</span><span class="n">scores_baseline</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MultipleKernelRidgeCV&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">scores_baseline</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;KernelRidgeCV&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$R^2$ generalization score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Histogram over targets&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Histogram over targets" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mkr_sklearn_api_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  24.671 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-multiple-kernel-ridge-plot-mkr-sklearn-api-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/9cc76a1174f5f9aacb39d3ce12768333/plot_mkr_sklearn_api.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_mkr_sklearn_api.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a6957dcff5e46ab03aee43c3fa7495dd/plot_mkr_sklearn_api.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_mkr_sklearn_api.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/_auto_examples/multiple_kernel_ridge/plot_mkr_sklearn_api.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>
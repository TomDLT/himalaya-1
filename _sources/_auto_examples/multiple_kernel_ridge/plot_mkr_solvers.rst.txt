
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_auto_examples/multiple_kernel_ridge/plot_mkr_solvers.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__auto_examples_multiple_kernel_ridge_plot_mkr_solvers.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__auto_examples_multiple_kernel_ridge_plot_mkr_solvers.py:


Multiple kernel ridge solvers
=============================
This example demonstrates the different strategies to solve the multiple kernel
ridge regression: the *random search*, and the *hyper-gradient descent*.

The *random-search* strategy samples some kernel weights vectors from a Dirichlet
distribution, then for each vector, it fits a ``KernelRidgeCV`` model and
computes a cross-validation score for all targets. Then it selects for each
target the kernel weight vector leading to the highest cross-validation score
(e.g. the highest R\ :sup:`2` value).
Extensively sampling the kernel weights space is exponentially expensive with
the number of kernels, therefore this method is computationally expensive for a
large number of kernels. However, since it reuses most of the computations for
all targets, it scales very well with the number of targets.

The *hyper-gradient descent* strategy takes a different route. It starts with
an initial kernel weights vector per target, and updates it iteratively
following the hyperparameter gradient, computed over cross-validation. As it
computes a hyper-gradient descent for each target, it is more expensive
computationally for large number of targets. However, the hyper-gradient
descent scales very well with the number of kernels.

.. GENERATED FROM PYTHON SOURCE LINES 24-39

.. code-block:: default

    import numpy as np
    import matplotlib.pyplot as plt

    from himalaya.backend import set_backend
    from himalaya.kernel_ridge import generate_dirichlet_samples

    from himalaya.kernel_ridge import KernelRidgeCV
    from himalaya.kernel_ridge import MultipleKernelRidgeCV
    from himalaya.kernel_ridge import Kernelizer
    from himalaya.kernel_ridge import ColumnKernelizer

    from sklearn.pipeline import make_pipeline
    from sklearn import set_config
    set_config(display='diagram')








.. GENERATED FROM PYTHON SOURCE LINES 41-42

In this example, we use the ``torch`` backend, and fit the model on GPU.

.. GENERATED FROM PYTHON SOURCE LINES 42-45

.. code-block:: default


    backend = set_backend("torch_cuda")








.. GENERATED FROM PYTHON SOURCE LINES 46-50

Generate a random dataset
-------------------------
We start by generating some arbitrary scalings per kernel and targets, using
samples on a Dirichlet distribution.

.. GENERATED FROM PYTHON SOURCE LINES 50-55

.. code-block:: default


    n_kernels = 3
    n_targets = 50
    n_clusters = 2








.. GENERATED FROM PYTHON SOURCE LINES 56-57

To create some clusters of weights, we take a few kernel weights samples..

.. GENERATED FROM PYTHON SOURCE LINES 57-61

.. code-block:: default

    kernel_weights_true = generate_dirichlet_samples(n_clusters, n_kernels,
                                                     concentration=[.3],
                                                     random_state=105)








.. GENERATED FROM PYTHON SOURCE LINES 62-63

.. then, we duplicate them, and add some noise, to get clusters.

.. GENERATED FROM PYTHON SOURCE LINES 63-73

.. code-block:: default

    noise = 0.05
    kernel_weights_true = backend.to_numpy(kernel_weights_true)
    kernel_weights_true = np.tile(kernel_weights_true,
                                  (n_targets // n_clusters, 1))
    kernel_weights_true += np.random.randn(n_targets, n_kernels) * noise

    # We finish with a projection on the simplex, making kernel weights sum to one.
    kernel_weights_true[kernel_weights_true < 0] = 0.
    kernel_weights_true /= np.sum(kernel_weights_true, 1)[:, None]








.. GENERATED FROM PYTHON SOURCE LINES 74-80

Then, we generate a random dataset, using the arbitrary scalings.

- Xs_train : list of arrays of shape (n_samples_train, n_features)
- Xs_test : list of arrays of shape (n_samples_test, n_features)
- Y_train : array of shape (n_samples_train, n_targets)
- Y_test : array of shape (n_repeat, n_samples_test, n_targets)

.. GENERATED FROM PYTHON SOURCE LINES 80-114

.. code-block:: default


    n_samples_train = 1000
    n_samples_test = 300
    n_features_list = np.full(n_kernels, fill_value=1000)

    Xs_train, Xs_test = [], []
    Y_train, Y_test = None, None
    for ii in range(n_kernels):
        n_features = n_features_list[ii]

        X_train = backend.randn(n_samples_train, n_features)
        X_test = backend.randn(n_samples_test, n_features)
        Xs_train.append(X_train)
        Xs_test.append(X_test)

        weights = backend.randn(n_features, n_targets) / n_features
        weights *= backend.asarray_like(kernel_weights_true[:, ii],
                                        ref=weights) ** 0.5

        if ii == 0:
            Y_train = X_train @ weights
            Y_test = X_test @ weights
        else:
            Y_train += X_train @ weights
            Y_test += X_test @ weights

    std = Y_train.std(0)[None]
    Y_train /= std
    Y_test /= std

    noise = 0.1
    Y_train += backend.randn(n_samples_train, n_targets) * noise
    Y_test += backend.randn(n_samples_test, n_targets) * noise








.. GENERATED FROM PYTHON SOURCE LINES 115-119

Define a ``ColumnKernelizer``
-----------------------------
We define a column kernelizer, which we will use to precompute the kernels in
a pipeline.

.. GENERATED FROM PYTHON SOURCE LINES 119-122

.. code-block:: default


    feature_names = ["space %d" % ii for ii in range(n_kernels)]








.. GENERATED FROM PYTHON SOURCE LINES 123-124

Concatenate the feature spaces

.. GENERATED FROM PYTHON SOURCE LINES 124-127

.. code-block:: default

    X_train = backend.asarray(backend.concatenate(Xs_train, 1), dtype="float32")
    X_test = backend.asarray(backend.concatenate(Xs_test, 1), dtype="float32")








.. GENERATED FROM PYTHON SOURCE LINES 128-129

Find the start and end of each feature space X in Xs

.. GENERATED FROM PYTHON SOURCE LINES 129-139

.. code-block:: default

    start_and_end = np.concatenate([[0], np.cumsum(n_features_list)])
    slices = [
        slice(start, end)
        for start, end in zip(start_and_end[:-1], start_and_end[1:])
    ]

    kernelizers = [(name, Kernelizer(), slice_)
                   for name, slice_ in zip(feature_names, slices)]
    column_kernelizer = ColumnKernelizer(kernelizers)








.. GENERATED FROM PYTHON SOURCE LINES 140-143

Define the models
-----------------
We define the first model, using the random search solver.

.. GENERATED FROM PYTHON SOURCE LINES 143-158

.. code-block:: default


    # (We pregenerate the Dirichlet random samples, to latter plot them.)
    kernel_weights_sampled = generate_dirichlet_samples(n_samples=20,
                                                        n_kernels=n_kernels,
                                                        concentration=[1.],
                                                        random_state=0)

    alphas = np.logspace(-10, 10, 41)
    solver_params = dict(n_iter=kernel_weights_sampled, alphas=alphas,
                         n_targets_batch=200, n_alphas_batch=20,
                         n_targets_batch_refit=200, jitter_alphas=True)

    model_1 = MultipleKernelRidgeCV(kernels="precomputed", solver="random_search",
                                    solver_params=solver_params)








.. GENERATED FROM PYTHON SOURCE LINES 159-160

We define the second model, using the hyper_gradient solver.

.. GENERATED FROM PYTHON SOURCE LINES 160-168

.. code-block:: default


    solver_params = dict(max_iter=80, n_targets_batch=200, tol=1e-3,
                         initial_deltas="ridgecv", max_iter_inner_hyper=1,
                         hyper_gradient_method="direct")

    model_2 = MultipleKernelRidgeCV(kernels="precomputed", solver="hyper_gradient",
                                    solver_params=solver_params)








.. GENERATED FROM PYTHON SOURCE LINES 169-170

We fit the two models on the train data.

.. GENERATED FROM PYTHON SOURCE LINES 170-174

.. code-block:: default


    pipe_1 = make_pipeline(column_kernelizer, model_1)
    pipe_1.fit(X_train, Y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [                                        ] 0% | 0.00 sec | 20 random sampling with cv |     [..                                      ] 5% | 0.25 sec | 20 random sampling with cv |     [....                                    ] 10% | 0.49 sec | 20 random sampling with cv |     [......                                  ] 15% | 0.68 sec | 20 random sampling with cv |     [........                                ] 20% | 0.93 sec | 20 random sampling with cv |     [..........                              ] 25% | 1.25 sec | 20 random sampling with cv |     [............                            ] 30% | 1.45 sec | 20 random sampling with cv |     [..............                          ] 35% | 1.64 sec | 20 random sampling with cv |     [................                        ] 40% | 1.96 sec | 20 random sampling with cv |     [..................                      ] 45% | 2.21 sec | 20 random sampling with cv |     [....................                    ] 50% | 2.40 sec | 20 random sampling with cv |     [......................                  ] 55% | 2.59 sec | 20 random sampling with cv |     [........................                ] 60% | 2.84 sec | 20 random sampling with cv |     [..........................              ] 65% | 3.03 sec | 20 random sampling with cv |     [............................            ] 70% | 3.27 sec | 20 random sampling with cv |     [..............................          ] 75% | 3.52 sec | 20 random sampling with cv |     [................................        ] 80% | 3.71 sec | 20 random sampling with cv |     [..................................      ] 85% | 3.90 sec | 20 random sampling with cv |     [....................................    ] 90% | 4.15 sec | 20 random sampling with cv |     [......................................  ] 95% | 4.34 sec | 20 random sampling with cv |     [........................................] 100% | 4.53 sec | 20 random sampling with cv | 


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-25599bdf-5890-4046-943d-0c188b92fdc2 {color: black;background-color: white;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 pre{padding: 0;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-toggleable {background-color: white;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-item {z-index: 1;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-parallel-item:only-child::after {width: 0;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-25599bdf-5890-4046-943d-0c188b92fdc2 div.sk-container {display: inline-block;position: relative;}</style><div id="sk-25599bdf-5890-4046-943d-0c188b92fdc2" class"sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="80d811b0-7008-415c-ac56-156699c1cb80" type="checkbox" ><label class="sk-toggleable__label" for="80d811b0-7008-415c-ac56-156699c1cb80">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('columnkernelizer',
                     ColumnKernelizer(transformers=[('space 0', Kernelizer(),
                                                     slice(0, 1000, None)),
                                                    ('space 1', Kernelizer(),
                                                     slice(1000, 2000, None)),
                                                    ('space 2', Kernelizer(),
                                                     slice(2000, 3000, None))])),
                    ('multiplekernelridgecv',
                     MultipleKernelRidgeCV(kernels='precomputed',
                                           solver_params={'alphas': array([1.00000000e-10, 3.16227766e-10, 1.00000000e-09,...
            [0.0967, 0.7845, 0.1188],
            [0.6945, 0.1770, 0.1285],
            [0.1278, 0.6189, 0.2533],
            [0.4615, 0.0104, 0.5280],
            [0.1979, 0.2006, 0.6015],
            [0.5289, 0.2058, 0.2653],
            [0.5074, 0.0264, 0.4662],
            [0.7480, 0.1591, 0.0930],
            [0.2262, 0.2698, 0.5040],
            [0.1123, 0.8667, 0.0209],
            [0.1595, 0.1198, 0.7207],
            [0.2433, 0.5232, 0.2335]], device='cuda:0', dtype=torch.float64),
                                                          'n_targets_batch': 200,
                                                          'n_targets_batch_refit': 200}))])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="eccee8c6-6249-400a-addd-be6b6b1a2ce1" type="checkbox" ><label class="sk-toggleable__label" for="eccee8c6-6249-400a-addd-be6b6b1a2ce1">columnkernelizer: ColumnKernelizer</label><div class="sk-toggleable__content"><pre>ColumnKernelizer(transformers=[('space 0', Kernelizer(), slice(0, 1000, None)),
                                   ('space 1', Kernelizer(),
                                    slice(1000, 2000, None)),
                                   ('space 2', Kernelizer(),
                                    slice(2000, 3000, None))])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="5fb2b958-a42f-405b-96c6-366402560fa2" type="checkbox" ><label class="sk-toggleable__label" for="5fb2b958-a42f-405b-96c6-366402560fa2">space 0</label><div class="sk-toggleable__content"><pre>slice(0, 1000, None)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="fa1f3591-26bc-4590-aafa-ba353b70557f" type="checkbox" ><label class="sk-toggleable__label" for="fa1f3591-26bc-4590-aafa-ba353b70557f">Kernelizer</label><div class="sk-toggleable__content"><pre>Kernelizer()</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="6dedc8a3-5bc3-4cb0-bbd1-d2e88b8ff26f" type="checkbox" ><label class="sk-toggleable__label" for="6dedc8a3-5bc3-4cb0-bbd1-d2e88b8ff26f">space 1</label><div class="sk-toggleable__content"><pre>slice(1000, 2000, None)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="8d1699d5-2bc3-40dd-a464-3c7586a1598c" type="checkbox" ><label class="sk-toggleable__label" for="8d1699d5-2bc3-40dd-a464-3c7586a1598c">Kernelizer</label><div class="sk-toggleable__content"><pre>Kernelizer()</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="daa68293-000e-4b46-bea3-b9b133bd7677" type="checkbox" ><label class="sk-toggleable__label" for="daa68293-000e-4b46-bea3-b9b133bd7677">space 2</label><div class="sk-toggleable__content"><pre>slice(2000, 3000, None)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="06a218c4-5a53-4fab-aacb-93acaa1c0b16" type="checkbox" ><label class="sk-toggleable__label" for="06a218c4-5a53-4fab-aacb-93acaa1c0b16">Kernelizer</label><div class="sk-toggleable__content"><pre>Kernelizer()</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="c78a45ce-1ccc-48ad-b926-9457dcea8c0d" type="checkbox" ><label class="sk-toggleable__label" for="c78a45ce-1ccc-48ad-b926-9457dcea8c0d">MultipleKernelRidgeCV</label><div class="sk-toggleable__content"><pre>MultipleKernelRidgeCV(kernels='precomputed',
                          solver_params={'alphas': array([1.00000000e-10, 3.16227766e-10, 1.00000000e-09, 3.16227766e-09,
           1.00000000e-08, 3.16227766e-08, 1.00000000e-07, 3.16227766e-07,
           1.00000000e-06, 3.16227766e-06, 1.00000000e-05, 3.16227766e-05,
           1.00000000e-04, 3.16227766e-04, 1.00000000e-03, 3.16227766e-03,
           1.00000000e-02, 3.16227766e-02, 1.000...
            [0.0967, 0.7845, 0.1188],
            [0.6945, 0.1770, 0.1285],
            [0.1278, 0.6189, 0.2533],
            [0.4615, 0.0104, 0.5280],
            [0.1979, 0.2006, 0.6015],
            [0.5289, 0.2058, 0.2653],
            [0.5074, 0.0264, 0.4662],
            [0.7480, 0.1591, 0.0930],
            [0.2262, 0.2698, 0.5040],
            [0.1123, 0.8667, 0.0209],
            [0.1595, 0.1198, 0.7207],
            [0.2433, 0.5232, 0.2335]], device='cuda:0', dtype=torch.float64),
                                         'n_targets_batch': 200,
                                         'n_targets_batch_refit': 200})</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 175-178

.. code-block:: default

    pipe_2 = make_pipeline(column_kernelizer, model_2)
    pipe_2.fit(X_train, Y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [                                        ] 0% | 0.00 sec | hypergradient_direct |     [                                        ] 0% | 0.00 sec | hypergradient_direct |     [                                        ] 1% | 0.12 sec | hypergradient_direct |     [.                                       ] 2% | 0.13 sec | hypergradient_direct |     [.                                       ] 4% | 0.15 sec | hypergradient_direct |     [..                                      ] 5% | 0.16 sec | hypergradient_direct |     [..                                      ] 6% | 0.17 sec | hypergradient_direct |     [...                                     ] 8% | 0.18 sec | hypergradient_direct |     [...                                     ] 9% | 0.20 sec | hypergradient_direct |     [....                                    ] 10% | 0.21 sec | hypergradient_direct |     [....                                    ] 11% | 0.22 sec | hypergradient_direct |     [.....                                   ] 12% | 0.23 sec | hypergradient_direct |     [.....                                   ] 14% | 0.25 sec | hypergradient_direct |     [......                                  ] 15% | 0.26 sec | hypergradient_direct |     [......                                  ] 16% | 0.27 sec | hypergradient_direct |     [.......                                 ] 18% | 0.28 sec | hypergradient_direct |     [.......                                 ] 19% | 0.29 sec | hypergradient_direct |     [........                                ] 20% | 0.31 sec | hypergradient_direct |     [........                                ] 21% | 0.32 sec | hypergradient_direct |     [.........                               ] 22% | 0.33 sec | hypergradient_direct |     [.........                               ] 24% | 0.34 sec | hypergradient_direct |     [..........                              ] 25% | 0.35 sec | hypergradient_direct |     [..........                              ] 26% | 0.37 sec | hypergradient_direct |     [...........                             ] 28% | 0.38 sec | hypergradient_direct |     [...........                             ] 29% | 0.39 sec | hypergradient_direct |     [............                            ] 30% | 0.40 sec | hypergradient_direct |     [............                            ] 31% | 0.42 sec | hypergradient_direct |     [.............                           ] 32% | 0.43 sec | hypergradient_direct |     [.............                           ] 34% | 0.44 sec | hypergradient_direct |     [..............                          ] 35% | 0.45 sec | hypergradient_direct |     [..............                          ] 36% | 0.46 sec | hypergradient_direct |     [...............                         ] 38% | 0.48 sec | hypergradient_direct |     [...............                         ] 39% | 0.49 sec | hypergradient_direct |     [................                        ] 40% | 0.50 sec | hypergradient_direct |     [................                        ] 41% | 0.51 sec | hypergradient_direct |     [.................                       ] 42% | 0.53 sec | hypergradient_direct |     [.................                       ] 44% | 0.54 sec | hypergradient_direct |     [..................                      ] 45% | 0.55 sec | hypergradient_direct |     [..................                      ] 46% | 0.56 sec | hypergradient_direct |     [...................                     ] 48% | 0.57 sec | hypergradient_direct |     [...................                     ] 49% | 0.59 sec | hypergradient_direct |     [....................                    ] 50% | 0.60 sec | hypergradient_direct |     [....................                    ] 51% | 0.61 sec | hypergradient_direct |     [.....................                   ] 52% | 0.62 sec | hypergradient_direct |     [.....................                   ] 54% | 0.64 sec | hypergradient_direct |     [......................                  ] 55% | 0.65 sec | hypergradient_direct |     [......................                  ] 56% | 0.66 sec | hypergradient_direct |     [.......................                 ] 57% | 0.67 sec | hypergradient_direct |     [.......................                 ] 59% | 0.69 sec | hypergradient_direct |     [........................                ] 60% | 0.70 sec | hypergradient_direct |     [........................                ] 61% | 0.71 sec | hypergradient_direct |     [.........................               ] 62% | 0.72 sec | hypergradient_direct |     [.........................               ] 64% | 0.74 sec | hypergradient_direct |     [..........................              ] 65% | 0.75 sec | hypergradient_direct |     [..........................              ] 66% | 0.76 sec | hypergradient_direct |     [...........................             ] 68% | 0.77 sec | hypergradient_direct |     [...........................             ] 69% | 0.78 sec | hypergradient_direct |     [............................            ] 70% | 0.80 sec | hypergradient_direct |     [............................            ] 71% | 0.81 sec | hypergradient_direct |     [.............................           ] 72% | 0.82 sec | hypergradient_direct |     [.............................           ] 74% | 0.83 sec | hypergradient_direct |     [..............................          ] 75% | 0.85 sec | hypergradient_direct |     [..............................          ] 76% | 0.86 sec | hypergradient_direct |     [...............................         ] 78% | 0.87 sec | hypergradient_direct |     [...............................         ] 79% | 0.88 sec | hypergradient_direct |     [................................        ] 80% | 0.89 sec | hypergradient_direct |     [................................        ] 81% | 0.91 sec | hypergradient_direct |     [.................................       ] 82% | 0.92 sec | hypergradient_direct |     [.................................       ] 84% | 0.93 sec | hypergradient_direct |     [..................................      ] 85% | 0.94 sec | hypergradient_direct |     [..................................      ] 86% | 0.96 sec | hypergradient_direct |     [...................................     ] 88% | 0.97 sec | hypergradient_direct |     [...................................     ] 89% | 0.98 sec | hypergradient_direct |     [....................................    ] 90% | 0.99 sec | hypergradient_direct |     [....................................    ] 91% | 1.01 sec | hypergradient_direct |     [.....................................   ] 92% | 1.02 sec | hypergradient_direct |     [.....................................   ] 94% | 1.03 sec | hypergradient_direct |     [......................................  ] 95% | 1.04 sec | hypergradient_direct |     [......................................  ] 96% | 1.05 sec | hypergradient_direct |     [....................................... ] 98% | 1.07 sec | hypergradient_direct |     [....................................... ] 99% | 1.08 sec | hypergradient_direct |     [........................................] 100% | 1.16 sec | hypergradient_direct | 


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 {color: black;background-color: white;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 pre{padding: 0;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-toggleable {background-color: white;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-estimator:hover {background-color: #d4ebff;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-item {z-index: 1;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-parallel-item:only-child::after {width: 0;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-104e353c-19b6-42c8-b2fd-f535d23bf740 div.sk-container {display: inline-block;position: relative;}</style><div id="sk-104e353c-19b6-42c8-b2fd-f535d23bf740" class"sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="3d564f3c-b81f-47e2-8234-243d176c9c19" type="checkbox" ><label class="sk-toggleable__label" for="3d564f3c-b81f-47e2-8234-243d176c9c19">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('columnkernelizer',
                     ColumnKernelizer(transformers=[('space 0', Kernelizer(),
                                                     slice(0, 1000, None)),
                                                    ('space 1', Kernelizer(),
                                                     slice(1000, 2000, None)),
                                                    ('space 2', Kernelizer(),
                                                     slice(2000, 3000, None))])),
                    ('multiplekernelridgecv',
                     MultipleKernelRidgeCV(kernels='precomputed',
                                           solver='hyper_gradient',
                                           solver_params={'hyper_gradient_method': 'direct',
                                                          'initial_deltas': 'ridgecv',
                                                          'max_iter': 80,
                                                          'max_iter_inner_hyper': 1,
                                                          'n_targets_batch': 200,
                                                          'tol': 0.001}))])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="987751b3-3c92-4cd8-9958-3cef7fcf8820" type="checkbox" ><label class="sk-toggleable__label" for="987751b3-3c92-4cd8-9958-3cef7fcf8820">columnkernelizer: ColumnKernelizer</label><div class="sk-toggleable__content"><pre>ColumnKernelizer(transformers=[('space 0', Kernelizer(), slice(0, 1000, None)),
                                   ('space 1', Kernelizer(),
                                    slice(1000, 2000, None)),
                                   ('space 2', Kernelizer(),
                                    slice(2000, 3000, None))])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="19e12a73-02ba-410b-9c78-1477ea9dc794" type="checkbox" ><label class="sk-toggleable__label" for="19e12a73-02ba-410b-9c78-1477ea9dc794">space 0</label><div class="sk-toggleable__content"><pre>slice(0, 1000, None)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="746942b3-ce27-4bdb-a198-8e3351be8207" type="checkbox" ><label class="sk-toggleable__label" for="746942b3-ce27-4bdb-a198-8e3351be8207">Kernelizer</label><div class="sk-toggleable__content"><pre>Kernelizer()</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="2d2d9ea8-c7cf-4275-8133-a09e0c1b4eb3" type="checkbox" ><label class="sk-toggleable__label" for="2d2d9ea8-c7cf-4275-8133-a09e0c1b4eb3">space 1</label><div class="sk-toggleable__content"><pre>slice(1000, 2000, None)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="cd250736-ad4a-49c0-82a0-0659e0589a72" type="checkbox" ><label class="sk-toggleable__label" for="cd250736-ad4a-49c0-82a0-0659e0589a72">Kernelizer</label><div class="sk-toggleable__content"><pre>Kernelizer()</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="43c49277-97a7-4361-8dc7-c6b203a818e9" type="checkbox" ><label class="sk-toggleable__label" for="43c49277-97a7-4361-8dc7-c6b203a818e9">space 2</label><div class="sk-toggleable__content"><pre>slice(2000, 3000, None)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="3a7be50a-d449-4f43-8f3d-7f67b30c0080" type="checkbox" ><label class="sk-toggleable__label" for="3a7be50a-d449-4f43-8f3d-7f67b30c0080">Kernelizer</label><div class="sk-toggleable__content"><pre>Kernelizer()</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="3a896939-e1ed-4e72-be0e-ca4ccbce9475" type="checkbox" ><label class="sk-toggleable__label" for="3a896939-e1ed-4e72-be0e-ca4ccbce9475">MultipleKernelRidgeCV</label><div class="sk-toggleable__content"><pre>MultipleKernelRidgeCV(kernels='precomputed', solver='hyper_gradient',
                          solver_params={'hyper_gradient_method': 'direct',
                                         'initial_deltas': 'ridgecv',
                                         'max_iter': 80, 'max_iter_inner_hyper': 1,
                                         'n_targets_batch': 200, 'tol': 0.001})</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 179-185

Plot the convergence curves
---------------------------
First convergence curve.

For the random search, ``cv_scores`` gives the scores for each sampled kernel
weights vector. The convergence curve is thus the current maximum for each target.

.. GENERATED FROM PYTHON SOURCE LINES 185-197

.. code-block:: default

    cv_scores = backend.to_numpy(pipe_1[1].cv_scores_)
    current_max = np.maximum.accumulate(cv_scores, axis=0)
    mean_current_max = np.mean(current_max, axis=1)

    x_array = np.arange(1, len(mean_current_max) + 1)
    plt.plot(x_array, mean_current_max, '-o')
    plt.grid("on")
    plt.xlabel("Number of kernel weights sampled")
    plt.ylabel("L2 negative loss (higher is better)")
    plt.title("Convergence curve, averaged over targets")
    plt.show()




.. image:: /_auto_examples/multiple_kernel_ridge/images/sphx_glr_plot_mkr_solvers_001.png
    :alt: Convergence curve, averaged over targets
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 198-199

Plot the second convergence curve.

.. GENERATED FROM PYTHON SOURCE LINES 199-211

.. code-block:: default


    cv_scores = backend.to_numpy(pipe_2[1].cv_scores_)
    mean_cv_scores = np.mean(cv_scores, axis=1)

    x_array = np.arange(1, len(mean_cv_scores) + 1)
    plt.plot(x_array, mean_cv_scores, '-o')
    plt.grid("on")
    plt.xlabel("Number of gradient iterations")
    plt.ylabel("L2 negative loss (higher is better)")
    plt.title("Convergence curve, averaged over targets")
    plt.show()




.. image:: /_auto_examples/multiple_kernel_ridge/images/sphx_glr_plot_mkr_solvers_002.png
    :alt: Convergence curve, averaged over targets
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 212-216

Compare with a ``KernelRidgeCV``
--------------------------------
Compare to a baseline ``KernelRidgeCV`` model with all the concatenated features.
Comparison is performed using the prediction scores on the test set.

.. GENERATED FROM PYTHON SOURCE LINES 216-221

.. code-block:: default


    # Fit the baseline model ``KernelRidgeCV``
    baseline = KernelRidgeCV(kernel="linear", alphas=alphas)
    baseline.fit(X_train, Y_train)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 {color: black;background-color: white;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 pre{padding: 0;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-toggleable {background-color: white;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-estimator:hover {background-color: #d4ebff;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-item {z-index: 1;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-parallel-item:only-child::after {width: 0;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-fe4bb02c-974f-48e9-8f23-fb558f04c696 div.sk-container {display: inline-block;position: relative;}</style><div id="sk-fe4bb02c-974f-48e9-8f23-fb558f04c696" class"sk-top-container"><div class="sk-container"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="cc5ae51c-b6f4-452b-b7e6-e72fee01aad7" type="checkbox" checked><label class="sk-toggleable__label" for="cc5ae51c-b6f4-452b-b7e6-e72fee01aad7">KernelRidgeCV</label><div class="sk-toggleable__content"><pre>KernelRidgeCV(alphas=array([1.00000000e-10, 3.16227766e-10, 1.00000000e-09, 3.16227766e-09,
           1.00000000e-08, 3.16227766e-08, 1.00000000e-07, 3.16227766e-07,
           1.00000000e-06, 3.16227766e-06, 1.00000000e-05, 3.16227766e-05,
           1.00000000e-04, 3.16227766e-04, 1.00000000e-03, 3.16227766e-03,
           1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,
           1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,
           1.00000000e+02, 3.16227766e+02, 1.00000000e+03, 3.16227766e+03,
           1.00000000e+04, 3.16227766e+04, 1.00000000e+05, 3.16227766e+05,
           1.00000000e+06, 3.16227766e+06, 1.00000000e+07, 3.16227766e+07,
           1.00000000e+08, 3.16227766e+08, 1.00000000e+09, 3.16227766e+09,
           1.00000000e+10]))</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 222-223

Compute scores of all models

.. GENERATED FROM PYTHON SOURCE LINES 223-232

.. code-block:: default

    scores_1 = pipe_1.score(X_test, Y_test)
    scores_1 = backend.to_numpy(scores_1)

    scores_2 = pipe_2.score(X_test, Y_test)
    scores_2 = backend.to_numpy(scores_2)

    scores_baseline = baseline.score(X_test, Y_test)
    scores_baseline = backend.to_numpy(scores_baseline)








.. GENERATED FROM PYTHON SOURCE LINES 233-234

Plot histograms

.. GENERATED FROM PYTHON SOURCE LINES 234-251

.. code-block:: default

    bins = np.linspace(
        np.min([scores_baseline.min(),
                scores_1.min(),
                scores_2.min()]),
        np.max([scores_baseline.max(),
                scores_1.max(),
                scores_2.max()]), 25)
    plt.hist(scores_1, bins, alpha=0.5,
             label="MultipleKernelRidgeCV(solver='random_search')")
    plt.hist(scores_2, bins, alpha=0.5,
             label="MultipleKernelRidgeCV(solver='hyper_gradient')")
    plt.hist(scores_baseline, bins, alpha=0.5, label="KernelRidgeCV")
    plt.xlabel(r"$R^2$ generalization score")
    plt.title("Histogram over targets")
    plt.legend()
    plt.show()




.. image:: /_auto_examples/multiple_kernel_ridge/images/sphx_glr_plot_mkr_solvers_003.png
    :alt: Histogram over targets
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 252-256

Generate trajectories
---------------------
Refit the second model with different number of iterations, just to plot the
trajectories.

.. GENERATED FROM PYTHON SOURCE LINES 256-269

.. code-block:: default


    all_kernel_weights_2 = [
        np.full((n_targets, n_kernels), fill_value=1. / n_kernels),
    ]
    for max_iter in np.unique(np.int_(np.logspace(0, np.log10(80), 3))):
        # change max_iter and refit from scratch
        pipe_2[1].solver_params['max_iter'] = max_iter
        pipe_2.fit(X_train, Y_train)

        kernel_weights_2 = np.exp(backend.to_numpy(pipe_2[1].deltas_.T))
        kernel_weights_2 /= kernel_weights_2.sum(1)[:, None]
        all_kernel_weights_2.append(kernel_weights_2)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [                                        ] 0% | 0.00 sec | hypergradient_direct |     [                                        ] 0% | 0.00 sec | hypergradient_direct |     [........................................] 100% | 0.15 sec | hypergradient_direct | 
    [                                        ] 0% | 0.00 sec | hypergradient_direct |     [                                        ] 0% | 0.00 sec | hypergradient_direct |     [.....                                   ] 12% | 0.12 sec | hypergradient_direct |     [..........                              ] 25% | 0.13 sec | hypergradient_direct |     [...............                         ] 38% | 0.15 sec | hypergradient_direct |     [....................                    ] 50% | 0.16 sec | hypergradient_direct |     [.........................               ] 62% | 0.17 sec | hypergradient_direct |     [..............................          ] 75% | 0.18 sec | hypergradient_direct |     [...................................     ] 88% | 0.20 sec | hypergradient_direct |     [........................................] 100% | 0.25 sec | hypergradient_direct | 
    [                                        ] 0% | 0.00 sec | hypergradient_direct |     [                                        ] 0% | 0.00 sec | hypergradient_direct |     [                                        ] 1% | 0.12 sec | hypergradient_direct |     [.                                       ] 3% | 0.13 sec | hypergradient_direct |     [.                                       ] 4% | 0.15 sec | hypergradient_direct |     [..                                      ] 5% | 0.16 sec | hypergradient_direct |     [..                                      ] 6% | 0.17 sec | hypergradient_direct |     [...                                     ] 8% | 0.18 sec | hypergradient_direct |     [...                                     ] 9% | 0.19 sec | hypergradient_direct |     [....                                    ] 10% | 0.21 sec | hypergradient_direct |     [....                                    ] 11% | 0.22 sec | hypergradient_direct |     [.....                                   ] 13% | 0.23 sec | hypergradient_direct |     [.....                                   ] 14% | 0.24 sec | hypergradient_direct |     [......                                  ] 15% | 0.26 sec | hypergradient_direct |     [......                                  ] 16% | 0.27 sec | hypergradient_direct |     [.......                                 ] 18% | 0.28 sec | hypergradient_direct |     [.......                                 ] 19% | 0.29 sec | hypergradient_direct |     [........                                ] 20% | 0.30 sec | hypergradient_direct |     [........                                ] 22% | 0.32 sec | hypergradient_direct |     [.........                               ] 23% | 0.33 sec | hypergradient_direct |     [.........                               ] 24% | 0.34 sec | hypergradient_direct |     [..........                              ] 25% | 0.35 sec | hypergradient_direct |     [..........                              ] 27% | 0.37 sec | hypergradient_direct |     [...........                             ] 28% | 0.38 sec | hypergradient_direct |     [...........                             ] 29% | 0.39 sec | hypergradient_direct |     [............                            ] 30% | 0.40 sec | hypergradient_direct |     [............                            ] 32% | 0.41 sec | hypergradient_direct |     [.............                           ] 33% | 0.43 sec | hypergradient_direct |     [.............                           ] 34% | 0.44 sec | hypergradient_direct |     [..............                          ] 35% | 0.45 sec | hypergradient_direct |     [..............                          ] 37% | 0.46 sec | hypergradient_direct |     [...............                         ] 38% | 0.48 sec | hypergradient_direct |     [...............                         ] 39% | 0.49 sec | hypergradient_direct |     [................                        ] 41% | 0.50 sec | hypergradient_direct |     [................                        ] 42% | 0.51 sec | hypergradient_direct |     [.................                       ] 43% | 0.52 sec | hypergradient_direct |     [.................                       ] 44% | 0.54 sec | hypergradient_direct |     [..................                      ] 46% | 0.55 sec | hypergradient_direct |     [..................                      ] 47% | 0.56 sec | hypergradient_direct |     [...................                     ] 48% | 0.57 sec | hypergradient_direct |     [...................                     ] 49% | 0.59 sec | hypergradient_direct |     [....................                    ] 51% | 0.60 sec | hypergradient_direct |     [....................                    ] 52% | 0.61 sec | hypergradient_direct |     [.....................                   ] 53% | 0.62 sec | hypergradient_direct |     [.....................                   ] 54% | 0.63 sec | hypergradient_direct |     [......................                  ] 56% | 0.65 sec | hypergradient_direct |     [......................                  ] 57% | 0.66 sec | hypergradient_direct |     [.......................                 ] 58% | 0.67 sec | hypergradient_direct |     [.......................                 ] 59% | 0.68 sec | hypergradient_direct |     [........................                ] 61% | 0.70 sec | hypergradient_direct |     [........................                ] 62% | 0.71 sec | hypergradient_direct |     [.........................               ] 63% | 0.72 sec | hypergradient_direct |     [.........................               ] 65% | 0.73 sec | hypergradient_direct |     [..........................              ] 66% | 0.74 sec | hypergradient_direct |     [..........................              ] 67% | 0.76 sec | hypergradient_direct |     [...........................             ] 68% | 0.77 sec | hypergradient_direct |     [...........................             ] 70% | 0.78 sec | hypergradient_direct |     [............................            ] 71% | 0.79 sec | hypergradient_direct |     [............................            ] 72% | 0.81 sec | hypergradient_direct |     [.............................           ] 73% | 0.82 sec | hypergradient_direct |     [.............................           ] 75% | 0.83 sec | hypergradient_direct |     [..............................          ] 76% | 0.84 sec | hypergradient_direct |     [..............................          ] 77% | 0.85 sec | hypergradient_direct |     [...............................         ] 78% | 0.87 sec | hypergradient_direct |     [...............................         ] 80% | 0.88 sec | hypergradient_direct |     [................................        ] 81% | 0.89 sec | hypergradient_direct |     [................................        ] 82% | 0.90 sec | hypergradient_direct |     [.................................       ] 84% | 0.92 sec | hypergradient_direct |     [.................................       ] 85% | 0.93 sec | hypergradient_direct |     [..................................      ] 86% | 0.94 sec | hypergradient_direct |     [..................................      ] 87% | 0.95 sec | hypergradient_direct |     [...................................     ] 89% | 0.96 sec | hypergradient_direct |     [...................................     ] 90% | 0.98 sec | hypergradient_direct |     [....................................    ] 91% | 0.99 sec | hypergradient_direct |     [....................................    ] 92% | 1.00 sec | hypergradient_direct |     [.....................................   ] 94% | 1.01 sec | hypergradient_direct |     [.....................................   ] 95% | 1.03 sec | hypergradient_direct |     [......................................  ] 96% | 1.04 sec | hypergradient_direct |     [......................................  ] 97% | 1.05 sec | hypergradient_direct |     [....................................... ] 99% | 1.06 sec | hypergradient_direct |     [........................................] 100% | 1.15 sec | hypergradient_direct | 




.. GENERATED FROM PYTHON SOURCE LINES 270-271

Get the normalized kernel weights for the first model

.. GENERATED FROM PYTHON SOURCE LINES 271-274

.. code-block:: default

    kernel_weights_1 = np.exp(backend.to_numpy(pipe_1[1].deltas_.T))
    kernel_weights_1 /= kernel_weights_1.sum(1)[:, None]








.. GENERATED FROM PYTHON SOURCE LINES 275-285

Plot on the simplex
-------------------
Finally, we visualize the obtained kernel weights vector, projected on the simplex.
The simplex is the space of positive weights that sum to one, and it has a
triangular shape in dimension 3.
We plot on three different panels:

- the kernel weights used in the simulated data
- the kernel weights sampled during random search, and the best ones
- the kernel weights trajectories obtained during hyper-gradient descent

.. GENERATED FROM PYTHON SOURCE LINES 285-359

.. code-block:: default



    def _create_simplex_projection_and_edges(ax):
        """Create a projection on the 3D simplex, and plot edges."""
        n_kernels = 3

        if ax is None:
            ax = plt.gca()

        # create a projection in 2D
        from sklearn.decomposition import PCA
        kernel_weights = generate_dirichlet_samples(10000, n_kernels,
                                                    concentration=[1.],
                                                    random_state=0)
        pca = PCA(2).fit(backend.to_numpy(kernel_weights))

        # add simplex edges
        edges = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]])
        edges = pca.transform(edges).T

        # add tripod at origin
        tripod_length = 0.15
        tripod = np.array([[0, 0, 0], [tripod_length, 0, 0], [0, 0, 0],
                           [0, tripod_length, 0], [0, 0, 0], [0, 0,
                                                              tripod_length]])
        tripod = pca.transform(tripod).T

        # add point legend
        points = np.array([[1, 0, 0], [0, 1, 0],
                           [0, 0, 1]])
        labels = points.copy()
        points = pca.transform(points * 1.15).T
        for (xx, yy), label in zip(points.T, labels):
            ax.text(xx, yy, str(label), horizontalalignment='center',
                    verticalalignment='center')

        if ax is None:
            plt.figure(figsize=(8, 8))
            ax = plt.gca()
        ax.plot(edges[0], edges[1], c='gray')
        ax.plot(tripod[0], tripod[1], c='gray')
        ax.axis('equal')
        ax.axis('off')
        return ax, pca


    def plot_simplex(X, ax=None, **kwargs):
        """Plot a set of points in the 3D simplex."""
        ax, pca = _create_simplex_projection_and_edges(ax=ax)

        Xt = pca.transform(X).T
        ax.scatter(Xt[0], Xt[1], **kwargs)
        ax.legend()
        return ax


    def plot_simplex_trajectory(Xs, ax=None):
        """Plot a series of trajectory in the 3D simplex."""
        ax, pca = _create_simplex_projection_and_edges(ax=ax)

        trajectories = []
        for Xi in Xs:
            Xt = pca.transform(Xi).T
            trajectories.append(Xt)
        trajectories = np.array(trajectories)

        for trajectory in trajectories.T:
            ax.plot(trajectory[0], trajectory[1], linewidth=1, color="C0",
                    zorder=1)
            ax.scatter(trajectory[0, -1], trajectory[1, -1], color="C1", zorder=2)

        return ax









.. GENERATED FROM PYTHON SOURCE LINES 360-385

.. code-block:: default

    fig, axs = plt.subplots(1, 3, figsize=(12, 4))

    # First panel
    ax = axs[0]
    ax.set_title("(a) Ground truth", y=0)
    plot_simplex(kernel_weights_true, ax=ax, color='C2',
                 label="true weights")

    # Second panel
    ax = axs[1]
    ax.set_title("(b) Random search", y=0)
    plot_simplex(backend.to_numpy(kernel_weights_sampled), ax=ax, marker='+',
                 label="random candidates", zorder=10)
    plot_simplex(kernel_weights_1, ax=axs[1], label="selected candidates")

    # Third panel
    ax = axs[2]
    ax.set_title("(c) Gradient descent", y=0)
    plot_simplex_trajectory(all_kernel_weights_2, ax=ax)
    ax.legend([ax.lines[2], ax.collections[0]],
              ['gradient trajectory', 'final point'])

    plt.tight_layout()
    # fig.savefig('simulation.pdf', dpi=150, bbox_inches='tight', pad_inches=0)
    plt.show()



.. image:: /_auto_examples/multiple_kernel_ridge/images/sphx_glr_plot_mkr_solvers_004.png
    :alt: (a) Ground truth, (b) Random search, (c) Gradient descent
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  9.095 seconds)


.. _sphx_glr_download__auto_examples_multiple_kernel_ridge_plot_mkr_solvers.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_mkr_solvers.py <plot_mkr_solvers.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_mkr_solvers.ipynb <plot_mkr_solvers.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
